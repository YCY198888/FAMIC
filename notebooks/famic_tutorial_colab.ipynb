{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FAMIC Model Tutorial (Google Colab)\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Load datasets from HuggingFace\n",
        "2. Load tokenizers for text preprocessing\n",
        "3. Initialize the FAMIC model architecture\n",
        "4. Load pretrained weights and evaluate the model\n",
        "\n",
        "## Setup for Google Colab\n",
        "\n",
        "This notebook is designed to run in Google Colab. It will automatically clone the repository and set up the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository and change directory\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Repository URL\n",
        "REPO_URL = \"https://github.com/YCY198888/FAMIC.git\"\n",
        "REPO_NAME = \"FAMIC\"\n",
        "\n",
        "# Clone the repository if it doesn't exist\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    print(f\"Cloning repository from {REPO_URL}...\")\n",
        "    os.system(f\"git clone {REPO_URL}\")\n",
        "    print(\"✓ Repository cloned successfully!\")\n",
        "else:\n",
        "    print(f\"✓ Repository already exists at {REPO_NAME}\")\n",
        "\n",
        "# Change to the repository directory\n",
        "os.chdir(REPO_NAME)\n",
        "project_root = Path().resolve()\n",
        "\n",
        "print(f\"\\n✓ Changed to repository directory: {project_root}\")\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "print(\"Installing dependencies from requirements.txt...\")\n",
        "%pip install -q -r requirements.txt\n",
        "print(\"✓ Dependencies installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add src to path\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Get the project root directory (current directory after cd)\n",
        "project_root = Path().resolve()\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Python path updated\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Import FAMIC modules\n",
        "from src.datasets import (\n",
        "    load_dataset_csv,\n",
        "    print_dataset_statistics,\n",
        "    report_dataset_statistics,\n",
        "    load_tokenizer,\n",
        "    get_dataset_info,\n",
        "    DATASET_REGISTRY\n",
        ")\n",
        "\n",
        "from src.model import (\n",
        "    FAMIC,\n",
        "    create_embedding_matrix,\n",
        "    initialize_model_blocks,\n",
        "    EMBEDDING_DIMENSIONS,\n",
        "    VOCAB_LENGTH,\n",
        "    MAX_LEN,\n",
        "    NUM_HEADS\n",
        ")\n",
        "\n",
        "from src.download_weights import (\n",
        "    download_all_weights,\n",
        "    load_pretrained_weights,\n",
        "    get_weights_path\n",
        ")\n",
        "\n",
        "print(\"✓ All imports successful!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clearing Cached Data\n",
        "\n",
        "If you need to re-download datasets (e.g., after corrections on HuggingFace), you can clear the cache:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clear cached dataset to force re-download\n",
        "# Uncomment the line below to clear cache for a specific dataset\n",
        "\n",
        "from src.datasets import clear_dataset_cache, clear_all_cache\n",
        "\n",
        "# Clear only the dataset cache\n",
        "#clear_dataset_cache(\"twitter\")\n",
        "\n",
        "# Or clear both dataset and tokenizer cache\n",
        "# clear_all_cache(\"twitter\")\n",
        "\n",
        "# Or clear everything including HuggingFace internal cache\n",
        "# clear_all_cache(\"twitter\", clear_hf_cache=True)\n",
        "\n",
        "print(\"Cache clearing functions are available.\")\n",
        "print(\"Uncomment the lines above to clear cache when needed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## HuggingFace Authentication\n",
        "\n",
        "**Important**: If the repository is private or gated, you need to authenticate with HuggingFace first.\n",
        "\n",
        "You have three options:\n",
        "\n",
        "1. **Set environment variable** (recommended):\n",
        "   ```python\n",
        "   import os\n",
        "   os.environ['HF_TOKEN'] = 'your_huggingface_token_here'\n",
        "   ```\n",
        "\n",
        "2. **Use the login function**:\n",
        "   ```python\n",
        "   from src.datasets import authenticate_huggingface\n",
        "   authenticate_huggingface(token='your_huggingface_token_here')\n",
        "   ```\n",
        "\n",
        "3. **Use HuggingFace CLI** (before starting Jupyter):\n",
        "   ```bash\n",
        "   huggingface-cli login\n",
        "   ```\n",
        "\n",
        "Get your token from: https://huggingface.co/settings/tokens\n",
        "\n",
        "**Note**: If you're not sure if authentication is needed, try loading the dataset first. The error message will tell you if authentication is required.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Authenticate with HuggingFace if needed\n",
        "# Uncomment and add your token if you get authentication errors\n",
        "\n",
        "# Option 1: Set environment variable\n",
        "# import os\n",
        "# os.environ['HF_TOKEN'] = 'your_huggingface_token_here'\n",
        "\n",
        "# Option 2: Use login function\n",
        "# from src.datasets import authenticate_huggingface\n",
        "# authenticate_huggingface(token='your_huggingface_token_here')\n",
        "\n",
        "# Option 3: If you've already logged in via CLI, you can skip this cell\n",
        "print(\"Authentication: If you get 401 errors, uncomment one of the options above\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Loading Datasets\n",
        "\n",
        "The FAMIC model supports two datasets:\n",
        "- **Twitter**: Twitter dataset cleaned in 2024\n",
        "- **Wine**: Wine dataset with 140k samples cleaned in 2025\n",
        "\n",
        "Both datasets are automatically downloaded from HuggingFace on first use and cached locally.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show available datasets\n",
        "print(\"Available datasets:\")\n",
        "for name, info in DATASET_REGISTRY.items():\n",
        "    print(f\"  - {name}: {info['name']}\")\n",
        "    print(f\"    Description: {info['description']}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose which dataset to load\n",
        "# Options: \"twitter\" or \"wine\"\n",
        "DATASET_NAME = \"wine\"  # Change this to \"wine\" to load the wine dataset\n",
        "\n",
        "print(f\"Loading {DATASET_NAME} dataset...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load the dataset\n",
        "df = load_dataset_csv(DATASET_NAME)\n",
        "\n",
        "# Display basic information\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get detailed dataset statistics\n",
        "print_dataset_statistics(DATASET_NAME, df=df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Loading Tokenizers\n",
        "\n",
        "Each dataset has its own tokenizer that was used during training. The tokenizers are also downloaded from HuggingFace.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the tokenizer for the selected dataset\n",
        "print(f\"Loading tokenizer for '{DATASET_NAME}' dataset...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "tokenizer = load_tokenizer(DATASET_NAME)\n",
        "\n",
        "# Display tokenizer information\n",
        "print(f\"\\nTokenizer loaded successfully!\")\n",
        "print(f\"Vocabulary size: {len(tokenizer.word_index) if hasattr(tokenizer, 'word_index') else 'N/A'}\")\n",
        "print(f\"OOV token: {tokenizer.oov_token if hasattr(tokenizer, 'oov_token') else 'N/A'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Tokenize some sample text\n",
        "if hasattr(df, 'columns'):\n",
        "    # Try to find a text column (common names)\n",
        "    text_columns = [col for col in df.columns if any(keyword in col.lower() \n",
        "                   for keyword in ['text', 'review', 'comment', 'content', 'tweet'])]\n",
        "    \n",
        "    if text_columns:\n",
        "        sample_text = df[text_columns[0]].iloc[0] if len(df) > 0 else \"This is a sample text.\"\n",
        "        print(f\"Sample text: {sample_text}\")\n",
        "        print(f\"\\nTokenizing sample text...\")\n",
        "        \n",
        "        # Tokenize\n",
        "        sequences = tokenizer.texts_to_sequences([sample_text])\n",
        "        print(f\"Tokenized sequence: {sequences[0]}\")\n",
        "        print(f\"Sequence length: {len(sequences[0])}\")\n",
        "    else:\n",
        "        print(\"No text column found. Please adjust the column name in the code above.\")\n",
        "        print(f\"Available columns: {list(df.columns)}\")\n",
        "else:\n",
        "    print(\"DataFrame not available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initializing the FAMIC Model\n",
        "\n",
        "Now we'll initialize the FAMIC model architecture. The model requires:\n",
        "- An embedding matrix (can be empty or pre-trained)\n",
        "- Model hyperparameters\n",
        "\n",
        "### 3.1 Create Embedding Matrix\n",
        "\n",
        "First, we create an embedding matrix. For now, we'll create an empty one that can be filled with pre-trained embeddings later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create embedding matrix\n",
        "# In practice, you would load pre-trained embeddings (e.g., Word2Vec, GloVe)\n",
        "# For now, we create an empty matrix that matches the expected dimensions\n",
        "\n",
        "embedding_dim = EMBEDDING_DIMENSIONS  # 300\n",
        "vocab_length = VOCAB_LENGTH  # 250000\n",
        "\n",
        "print(f\"Creating embedding matrix...\")\n",
        "print(f\"  Vocabulary size: {vocab_length + 1}\")\n",
        "print(f\"  Embedding dimension: {embedding_dim}\")\n",
        "\n",
        "embedding_matrix = create_embedding_matrix(\n",
        "    vocab_length=vocab_length,\n",
        "    embedding_dim=embedding_dim\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Embedding matrix created\")\n",
        "print(f\"  Shape: {embedding_matrix.shape}\")\n",
        "print(f\"  Dtype: {embedding_matrix.dtype}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Initialize Model Blocks\n",
        "\n",
        "We can initialize individual model blocks or the complete FAMIC model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize individual model blocks\n",
        "print(\"Initializing FAMIC model blocks...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "blocks = initialize_model_blocks(\n",
        "    embedding_matrix=embedding_matrix,\n",
        "    hidden_dim=EMBEDDING_DIMENSIONS,\n",
        "    n_layers=2,\n",
        "    max_relative_position_mask=2,\n",
        "    max_relative_position_shift=5,\n",
        "    pivot=0.5,\n",
        "    num_heads=NUM_HEADS,\n",
        "    drop_prob=0.5,\n",
        "    digits_dim=1\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Model blocks initialized:\")\n",
        "for block_name in blocks.keys():\n",
        "    print(f\"  - {block_name}: {type(blocks[block_name]).__name__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the complete FAMIC model\n",
        "print(\"Initializing complete FAMIC model...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = FAMIC(\n",
        "    embedding_matrix=embedding_matrix,\n",
        "    hidden_dim=EMBEDDING_DIMENSIONS,\n",
        "    n_layers=2,\n",
        "    max_relative_position_mask=2,\n",
        "    max_relative_position_shift=5,\n",
        "    pivot=0.5,\n",
        "    num_heads=NUM_HEADS,\n",
        "    drop_prob=0.5,\n",
        "    digits_dim=1\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "print(\"\\n✓ FAMIC model initialized successfully!\")\n",
        "print(f\"  Model device: {next(model.parameters()).device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Load Pretrained Weights from HuggingFace\n",
        "\n",
        "Now we can load pretrained weights for the selected dataset. The weights are automatically downloaded from HuggingFace if not already cached.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pretrained weights from HuggingFace\n",
        "# This will automatically download weights if not already cached\n",
        "print(\"Loading pretrained weights from HuggingFace...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from src.download_weights import load_pretrained_weights\n",
        "\n",
        "# Load weights into the model blocks\n",
        "model_blocks_loaded = load_pretrained_weights(\n",
        "    model_blocks={\n",
        "        'embeds': model.embeds,\n",
        "        'sentiment': model.sentiment,\n",
        "        'mask': model.mask,\n",
        "        'shifter1': model.shifter1,\n",
        "        'shifter2': model.shifter2,\n",
        "        'synthesizer': model.synthesizer\n",
        "    },\n",
        "    dataset_name=DATASET_NAME,\n",
        "    cache_dir=\"models\",\n",
        "    version=\"v2\",  # Model version\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Pretrained weights loaded successfully!\")\n",
        "print(f\"  Model is ready for inference on '{DATASET_NAME}' dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Alternative: Initialize model with pretrained weights directly**\n",
        "\n",
        "You can also create a model and load weights in one step:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative: Create model with pretrained weights in one step\n",
        "print(\"Alternative method: Loading model with pretrained weights...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create a new model instance with pretrained weights\n",
        "model_pretrained = FAMIC.from_pretrained_huggingface(\n",
        "    dataset_name=DATASET_NAME,\n",
        "    embedding_matrix=embedding_matrix,\n",
        "    cache_dir=\"models\",\n",
        "    version=\"v2\",\n",
        "    device=device,\n",
        "    hidden_dim=EMBEDDING_DIMENSIONS,\n",
        "    n_layers=2,\n",
        "    max_relative_position_mask=2,\n",
        "    max_relative_position_shift=5,\n",
        "    pivot=0.5,\n",
        "    num_heads=NUM_HEADS,\n",
        "    drop_prob=0.5,\n",
        "    digits_dim=1\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Model with pretrained weights created successfully!\")\n",
        "print(f\"  Model device: {next(model_pretrained.parameters()).device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Creating Train/Validation/Test Splits\n",
        "\n",
        "For evaluation, we need to split the dataset into train, validation, and test sets. The model is trained on the training set, early stopped using the validation set, and finally evaluated on the test set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note**: If you get an `ImportError` for `WordDataset`, restart your kernel or run the cell below to reload the module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Force reload the datasets module to pick up new classes\n",
        "import importlib\n",
        "import sys\n",
        "\n",
        "# Remove the module from cache if it exists\n",
        "if 'src.datasets' in sys.modules:\n",
        "    del sys.modules['src.datasets']\n",
        "\n",
        "# Re-import\n",
        "from src.datasets import (\n",
        "    WordDataset,\n",
        "    create_train_val_test_split,\n",
        "    create_dataloaders,\n",
        "    load_dataset_csv,\n",
        "    load_tokenizer\n",
        ")\n",
        "\n",
        "print(\"✓ Module reloaded successfully\")\n",
        "print(\"✓ WordDataset and other functions are now available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create train/validation/test splits and dataloaders\n",
        "from src.datasets import create_dataloaders, create_train_val_test_split\n",
        "\n",
        "# Configuration\n",
        "MAX_LEN = 150  # Maximum sequence length\n",
        "BATCH_SIZE = 100  # Batch size for training/evaluation\n",
        "SEED = 2025  # Random seed for reproducibility\n",
        "\n",
        "# Column names (adjust these based on your dataset structure)\n",
        "# Common names: 'text', 'preprocessed_text', 'review', 'tweet', etc.\n",
        "TEXT_COLUMN = \"preprocessed_text\"  # Adjust if your dataset uses a different column name\n",
        "LABEL_COLUMN = \"labels\"  # Adjust if your dataset uses a different column name\n",
        "\n",
        "print(f\"Creating dataloaders for '{DATASET_NAME}' dataset...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader, val_loader, test_loader = create_dataloaders(\n",
        "    dataset_name=DATASET_NAME,\n",
        "    text_column=TEXT_COLUMN,\n",
        "    label_column=LABEL_COLUMN,\n",
        "    max_len=MAX_LEN,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    test_size=0.1,  # 10% for test\n",
        "    val_size=0.5,   # 50% of test set for validation (so 5% total)\n",
        "    random_state=SEED,\n",
        "    num_workers=0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify the dataloaders work\n",
        "print(\"\\nTesting dataloaders...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Get a sample batch from train loader\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(f\"\\nSample batch from train loader:\")\n",
        "print(f\"  word_ids shape: {sample_batch['word_ids'].shape}\")\n",
        "print(f\"  attention_mask shape: {sample_batch['attention_mask'].shape}\")\n",
        "print(f\"  labels shape: {sample_batch['labels'].shape}\")\n",
        "print(f\"  Batch size: {sample_batch['word_ids'].shape[0]}\")\n",
        "print(f\"  Sequence length: {sample_batch['word_ids'].shape[1]}\")\n",
        "\n",
        "# Show a sample\n",
        "print(f\"\\nSample from batch:\")\n",
        "print(f\"  First word_ids (first 20 tokens): {sample_batch['word_ids'][0][:20].tolist()}\")\n",
        "print(f\"  First attention_mask (first 20): {sample_batch['attention_mask'][0][:20].tolist()}\")\n",
        "print(f\"  First label: {sample_batch['labels'][0].item()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluating the Model\n",
        "\n",
        "Now that we have the model, pretrained weights, and test dataloader, we can evaluate the model performance on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model on test set\n",
        "from src.evaluate import evaluate_model\n",
        "import torch.nn as nn\n",
        "\n",
        "# Set evaluation flags (these should match how the model was trained)\n",
        "USE_MASK = True\n",
        "USE_SHIFT1 = True\n",
        "USE_SHIFT2 = True\n",
        "\n",
        "# Use the model with pretrained weights (model_pretrained from earlier)\n",
        "# Or use the model after loading weights (model from earlier)\n",
        "\n",
        "print(\"Evaluating model on test set...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Define loss function (BCEWithLogitsLoss for binary classification)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Evaluate on test set\n",
        "test_metrics = evaluate_model(\n",
        "    model=model_pretrained,  # Use the model with pretrained weights\n",
        "    dataloader=test_loader,\n",
        "    device=device,\n",
        "    criterion=criterion,\n",
        "    use_mask=USE_MASK,\n",
        "    use_shift1=USE_SHIFT1,\n",
        "    use_shift2=USE_SHIFT2,\n",
        "    return_loss=True\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Evaluation complete!\")\n",
        "print(f\"Test Accuracy: {test_metrics['accuracy']:.4f}\")\n",
        "print(f\"Test F1-Score: {test_metrics['f1_score']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Detailed Evaluation Metrics\n",
        "\n",
        "Let's examine the detailed evaluation results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display detailed evaluation metrics\n",
        "print(\"=\"*70)\n",
        "print(\"DETAILED EVALUATION METRICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nDataset: {DATASET_NAME}\")\n",
        "print(f\"Evaluation Configuration:\")\n",
        "print(f\"  Use Mask: {USE_MASK}\")\n",
        "print(f\"  Use Shifter 1: {USE_SHIFT1}\")\n",
        "print(f\"  Use Shifter 2: {USE_SHIFT2}\")\n",
        "print(f\"\\nPerformance Metrics:\")\n",
        "print(f\"  Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {test_metrics['precision']:.4f}\")\n",
        "print(f\"  Recall:    {test_metrics['recall']:.4f}\")\n",
        "print(f\"  F1-Score:  {test_metrics['f1_score']:.4f}\")\n",
        "if 'loss' in test_metrics:\n",
        "    print(f\"  Loss:      {test_metrics['loss']:.4f}\")\n",
        "\n",
        "print(f\"\\nConfusion Matrix Breakdown:\")\n",
        "print(f\"  True Positives (TP):  {test_metrics['TP']}\")\n",
        "print(f\"  True Negatives (TN):  {test_metrics['TN']}\")\n",
        "print(f\"  False Positives (FP): {test_metrics['FP']}\")\n",
        "print(f\"  False Negatives (FN): {test_metrics['FN']}\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Get predictions and true labels from the metrics\n",
        "# Note: We need to reconstruct these from the confusion matrix or re-run evaluation\n",
        "# For now, let's create a simple report based on the confusion matrix\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Calculate per-class metrics from confusion matrix\n",
        "cm = test_metrics['confusion_matrix']\n",
        "TN, FP, FN, TP = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
        "\n",
        "# Calculate per-class precision, recall, F1\n",
        "precision_class0 = TN / (TN + FN + 1e-12)  # Precision for class 0\n",
        "recall_class0 = TN / (TN + FP + 1e-12)     # Recall for class 0\n",
        "f1_class0 = 2 * precision_class0 * recall_class0 / (precision_class0 + recall_class0 + 1e-12)\n",
        "\n",
        "precision_class1 = TP / (TP + FP + 1e-12)  # Precision for class 1\n",
        "recall_class1 = TP / (TP + FN + 1e-12)     # Recall for class 1\n",
        "f1_class1 = 2 * precision_class1 * recall_class1 / (precision_class1 + recall_class1 + 1e-12)\n",
        "\n",
        "print(f\"\\nClass 0 (Negative):\")\n",
        "print(f\"  Precision: {precision_class0:.4f}\")\n",
        "print(f\"  Recall:    {recall_class0:.4f}\")\n",
        "print(f\"  F1-Score:  {f1_class0:.4f}\")\n",
        "print(f\"  Support:   {TN + FP}\")\n",
        "\n",
        "print(f\"\\nClass 1 (Positive):\")\n",
        "print(f\"  Precision: {precision_class1:.4f}\")\n",
        "print(f\"  Recall:    {recall_class1:.4f}\")\n",
        "print(f\"  F1-Score:  {f1_class1:.4f}\")\n",
        "print(f\"  Support:   {TP + FN}\")\n",
        "\n",
        "print(f\"\\nOverall:\")\n",
        "print(f\"  Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
        "print(f\"  Total:     {TN + FP + TP + FN}\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Evaluation Summary\n",
        "\n",
        "Summary of the evaluation results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a summary dictionary for easy access\n",
        "evaluation_summary = {\n",
        "    'dataset': DATASET_NAME,\n",
        "    'configuration': {\n",
        "        'use_mask': USE_MASK,\n",
        "        'use_shift1': USE_SHIFT1,\n",
        "        'use_shift2': USE_SHIFT2\n",
        "    },\n",
        "    'metrics': {\n",
        "        'accuracy': test_metrics['accuracy'],\n",
        "        'precision': test_metrics['precision'],\n",
        "        'recall': test_metrics['recall'],\n",
        "        'f1_score': test_metrics['f1_score']\n",
        "    },\n",
        "    'confusion_matrix': {\n",
        "        'TP': test_metrics['TP'],\n",
        "        'TN': test_metrics['TN'],\n",
        "        'FP': test_metrics['FP'],\n",
        "        'FN': test_metrics['FN']\n",
        "    }\n",
        "}\n",
        "\n",
        "if 'loss' in test_metrics:\n",
        "    evaluation_summary['metrics']['loss'] = test_metrics['loss']\n",
        "\n",
        "print(\"Evaluation Summary:\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Dataset: {evaluation_summary['dataset']}\")\n",
        "print(f\"\\nConfiguration:\")\n",
        "for key, value in evaluation_summary['configuration'].items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "print(f\"\\nMetrics:\")\n",
        "for key, value in evaluation_summary['metrics'].items():\n",
        "    print(f\"  {key}: {value:.4f}\")\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "for key, value in evaluation_summary['confusion_matrix'].items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Store summary for later use\n",
        "print(\"\\n✓ Evaluation summary stored in 'evaluation_summary' variable\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize confusion matrix\n",
        "from src.evaluate import plot_confusion_matrix\n",
        "import os\n",
        "\n",
        "# Create results directory if it doesn't exist\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "\n",
        "plot_confusion_matrix(\n",
        "    confusion_matrix=test_metrics['confusion_matrix'],\n",
        "    class_names=[\"Negative\", \"Positive\"],  # Adjust based on your dataset\n",
        "    save_path=\"results/test_confusion_matrix.png\",\n",
        "    title=f\"Test Set Confusion Matrix - {DATASET_NAME}\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. ✅ **Cloning the repository** and setting up the environment in Google Colab\n",
        "2. ✅ **Loading datasets** from HuggingFace with automatic caching\n",
        "3. ✅ **Loading tokenizers** for text preprocessing\n",
        "4. ✅ **Initializing the FAMIC model** with all its components\n",
        "5. ✅ **Loading pretrained weights** from HuggingFace for Twitter and Wine datasets\n",
        "6. ✅ **Creating train/validation/test splits** with reproducible random seed (2025)\n",
        "7. ✅ **Creating PyTorch DataLoaders** for model training and evaluation\n",
        "8. ✅ **Evaluating the model** on the test set with comprehensive metrics\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Use the model for inference on new data\n",
        "- Experiment with different datasets (twitter/wine)\n",
        "- Fine-tune the model on your own data\n",
        "- Explore the model's interpretability features\n",
        "\n",
        "### Notes\n",
        "\n",
        "- Datasets are cached in the `data/` directory after first download\n",
        "- Tokenizers are cached in the `data/tokenizers/` directory\n",
        "- Model weights are cached in the `models/{dataset_name}/` directory\n",
        "- Data splits use random seed 2025 for reproducibility\n",
        "- Default split: 90% train, 5% validation, 5% test\n",
        "- Make sure to use the correct tokenizer and weights for each dataset\n",
        "- Weights are automatically downloaded from HuggingFace on first use\n",
        "- In Colab, files are saved to the `/content/FAMIC/` directory\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
